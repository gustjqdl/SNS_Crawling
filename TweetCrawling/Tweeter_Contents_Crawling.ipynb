{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time \n",
    "import requests \n",
    "from selenium import webdriver \n",
    "import numpy as np\n",
    "import random\n",
    "from bs4 import BeautifulSoup \n",
    "from urllib.parse import quote_plus\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def scroll_pause_time():\n",
    "    num = np.random.randint(5)+1\n",
    "    scroll_pause_time = num\n",
    "    \n",
    "    return scroll_pause_time\n",
    "\n",
    "def tweet_crawler(keyword) :\n",
    "    global Crawling_Contents\n",
    "    Tweet_Contents =pd.DataFrame()\n",
    "    #path = os.path.realpath(os.path.dirname(__file__))\n",
    "    #dataFile = open(os.path.join(path,\"{}\".format(keyword)), encoding='utf-8-sig', mode ='at')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #My tweeter account \n",
    "    Tweeter_Account = {'id':\"****\", \"pw\":'*****'}\n",
    "    \n",
    "   \n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    #options.add_argument('headless')\n",
    "    \n",
    "    \n",
    "    # path 지정 \n",
    "    path = [\"크롤링_작업중\"]\n",
    "    path = [dir.replace(\"/\", \"\") for dir in path]\n",
    "    path = os.path.join(os.path.abspath(''),*path)\n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path=os.path.join(path,'chromedriver') , chrome_options=options)\n",
    "    \n",
    "    #base_url = 'https://mobile.twitter.com/search?q=%%'\n",
    "    #base_url = 'https://mobile.twitter.com/search?q=%'\n",
    "    #base_url2 = '&src=typed_query&f=live'\n",
    "    #quote_keyword = quote_plus(keyword)\n",
    "    \n",
    "    #keyword_URL = base_url+quote_keyword+base_url2\n",
    "    \n",
    "    \n",
    "    #트위터 로그인 \n",
    "    \n",
    "    driver.get('https://mobile.twitter.com/login?lang=ko')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    user_id = driver.find_element_by_name(\"session[username_or_email]\")\n",
    "    user_pw = driver.find_element_by_name(\"session[password]\")\n",
    "    \n",
    "    user_id.send_keys(Tweeter_Account['id'])\n",
    "    user_pw.send_keys(Tweeter_Account['pw'])\n",
    "    driver.implicitly_wait(3)\n",
    "    \n",
    "    driver.find_element_by_xpath('//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div[2]/form/div/div[3]/div/div/span/span').click()\n",
    "    driver.implicitly_wait(3)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    search_input = wait.until(ec.visibility_of_element_located((By.XPATH, \"//div/input[@data-testid='SearchBox_Search_Input']\")))\n",
    "\n",
    "    search_input.clear() \n",
    "    search_input.send_keys(keyword + Keys.ENTER)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    #최신순\n",
    "    driver.find_element_by_xpath('//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[1]/div[2]/nav/div/div[2]/div/div[2]/a/div').click()\n",
    "    \n",
    "    time.sleep(3)\n",
    "    # 마지막 스크롤 지정 \n",
    "    last_height= 0 \n",
    "    \n",
    "    # 수집할 객체 생성 \n",
    "    Crawling_Contents=dict()\n",
    "    Crawling_Contents['content'] = []\n",
    "    Crawling_Contents['date'] = []\n",
    "\n",
    "    \n",
    "    \n",
    "    while True : \n",
    "        #화면 최하단으로 스크롤 다운 \n",
    "        \n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        #페이지 로드 대기 \n",
    "  \n",
    "        \n",
    "        time.sleep(scroll_pause_time())\n",
    "        # 다시 절반을 더 내림 \n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight-50);')\n",
    "        time.sleep(scroll_pause_time())\n",
    "        \n",
    "        \n",
    "        new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        \n",
    "        if new_height ==last_height : \n",
    "            break \n",
    "            \n",
    "        \n",
    "        last_height = new_height \n",
    "        \n",
    "        \n",
    "        post_element_xpath = '//div/div/article/div/div'\n",
    "        \n",
    "        post_list = driver.find_elements_by_xpath(post_element_xpath) \n",
    "        post_text = [x.text for x in post_list]\n",
    "    \n",
    "        for i in post_text: \n",
    "            \n",
    "            try:\n",
    "                date = i.split('\\n')[3]\n",
    "                text = i.split('\\n')[4]\n",
    "\n",
    "                Crawling_Contents['content'].append(text)\n",
    "                Crawling_Contents['date'].append(date)\n",
    "\n",
    "            except: \n",
    "                pass \n",
    "            \n",
    "\n",
    "    Tweet_Contents['date'] = Crawling_Contents['date']\n",
    "    Tweet_Contents['Content'] = Crawling_Contents['content']  \n",
    "\n",
    "    Tweet_Contents.to_csv('Tweet_Contents.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    return Tweet_Contents\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_crawler('키워드 입력')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무한 스크롤이므로 중간에 멈추고 따로 수집하였음 \n",
    "\n",
    "Tweet_Contents =pd.DataFrame()\n",
    "\n",
    "Tweet_Contents['date'] = Crawling_Contents['date']\n",
    "Tweet_Contents['Content'] = Crawling_Contents['content']  \n",
    "\n",
    "Tweet_Contents.to_csv('Tweet_Contents.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
